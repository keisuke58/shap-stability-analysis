{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02: Model Training\n",
    "\n",
    "**Student**: Keisuke Nishioka (Matrikelnummer: 10081049)  \n",
    "**Project**: Stability and Faithfulness Analysis of SHAP Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from models import (\n",
    "    train_xgboost, train_random_forest, train_logistic_regression,\n",
    "    get_task_type, save_model\n",
    ")\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv').squeeze()\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv').squeeze()\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models with Multiple Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine task type\n",
    "task = get_task_type(y_train)\n",
    "print(f\"Task type: {task}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_models = {}\n",
    "\n",
    "for seed in config.RANDOM_SEEDS:\n",
    "    print(f\"Training XGBoost with seed {seed}...\")\n",
    "    model = train_xgboost(\n",
    "        X_train, y_train, \n",
    "        task=task, \n",
    "        random_state=seed\n",
    "    )\n",
    "    xgboost_models[seed] = model\n",
    "    \n",
    "    # Save model\n",
    "    save_model(model, f'../results/models/xgboost_seed_{seed}.pkl')\n",
    "\n",
    "print(f\"\\nTrained {len(xgboost_models)} XGBoost models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_models = {}\n",
    "\n",
    "for seed in config.RANDOM_SEEDS:\n",
    "    print(f\"Training Random Forest with seed {seed}...\")\n",
    "    model = train_random_forest(\n",
    "        X_train, y_train,\n",
    "        task=task,\n",
    "        random_state=seed\n",
    "    )\n",
    "    rf_models[seed] = model\n",
    "    \n",
    "    # Save model\n",
    "    save_model(model, f'../results/models/random_forest_seed_{seed}.pkl')\n",
    "\n",
    "print(f\"\\nTrained {len(rf_models)} Random Forest models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_models = {}\n",
    "\n",
    "for seed in config.RANDOM_SEEDS:\n",
    "    print(f\"Training Logistic Regression with seed {seed}...\")\n",
    "    model = train_logistic_regression(\n",
    "        X_train, y_train,\n",
    "        random_state=seed\n",
    "    )\n",
    "    lr_models[seed] = model\n",
    "    \n",
    "    # Save model\n",
    "    save_model(model, f'../results/models/logistic_regression_seed_{seed}.pkl')\n",
    "\n",
    "print(f\"\\nTrained {len(lr_models)} Logistic Regression models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, task='classification'):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if task == 'classification':\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            y_proba = model.predict_proba(X_test)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "            return {'accuracy': acc, 'auc': auc}\n",
    "        return {'accuracy': acc}\n",
    "    else:\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        return {'mse': mse, 'r2': r2}\n",
    "\n",
    "# Evaluate all models\n",
    "results = {}\n",
    "for model_name, models_dict in [('XGBoost', xgboost_models), \n",
    "                                 ('Random Forest', rf_models),\n",
    "                                 ('Logistic Regression', lr_models)]:\n",
    "    model_results = []\n",
    "    for seed, model in models_dict.items():\n",
    "        metrics = evaluate_model(model, X_test, y_test, task=task)\n",
    "        metrics['seed'] = seed\n",
    "        model_results.append(metrics)\n",
    "    results[model_name] = pd.DataFrame(model_results)\n",
    "\n",
    "# Display results\n",
    "for model_name, df in results.items():\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
