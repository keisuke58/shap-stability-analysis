# データサブサンプリング分析 - 実行中

## 📊 現在のデータセット

**Adult Income Dataset**
- サンプル数: 32,561
- 特徴量数: 100
- タスク: 分類（2クラス）

---

## 🔄 実行中の分析

### データサブサンプリング分析

**設定**:
- **サブサンプリング率**: 50%, 75%, 100%（3パターン）
- **ランダムシード**: 10個（精度向上のため）
- **テストサンプル数**: 50（30から増加）
- **モデルパラメータ**: 増加（精度向上）

**実行内容**:
1. 各サブサンプリング率で：
   - XGBoost: 10モデル訓練（n_estimators=100, max_depth=6）
   - Random Forest: 10モデル訓練（n_estimators=100, max_depth=10）
   - Logistic Regression: 10モデル訓練
   - SHAP説明生成（TreeSHAP + KernelSHAP）
   - 安定性分析

2. サブサンプリング率間の比較
3. 可視化作成

---

## ⏱️ 実行時間見積もり

### 各サブサンプリング率あたり

| ステップ | 時間（CPU環境） |
|---------|----------------|
| モデル訓練（3モデル×10シード） | 約10-15分 |
| TreeSHAP（XGBoost, RF×10シード） | 約10-15分 |
| KernelSHAP（Logistic Regression×10シード） | 約30-60分 |
| 安定性分析 | 約2-3分 |

**1サブサンプリング率あたり**: 約50-90分

### 全体（3サブサンプリング率）

**合計**: 約2.5-4.5時間

---

## 📊 期待される結果

### 分析内容

1. **サンプルサイズ効果の分析**
   - 訓練データサイズがSHAP説明の安定性に与える影響
   - より多くのデータでより安定するか

2. **モデル間比較**
   - 各サブサンプリング率でのモデル間比較
   - どのモデルがサンプルサイズの影響を受けやすいか

3. **実用的な推奨事項**
   - 最小限のデータサイズで安定した説明を得る方法
   - データサイズと安定性のトレードオフ

---

## 🔍 進行状況の確認

```bash
# 進行状況を確認
python check_progress.py
```

---

## 📁 生成されるファイル

### 結果テーブル
- `results/tables/subsampling_comparison.csv`

### 可視化
- `results/figures/subsampling_analysis.png`

---

## ⚠️ 注意事項

- **実行時間**: 約2.5-4.5時間かかります
- **KernelSHAP**: Logistic RegressionのSHAP計算が最も時間がかかります
- **CPU使用率**: 高負荷がかかります

---

*実行開始: バックグラウンドで実行中*
